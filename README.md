# Artificial-Neural-Network-model-for-calculating-Energy-Output
It comes under deep learning.The basic building blocks of artificial neural network is neuron.
The framework involves input layer where each feature of the dataset occupies one neuron/node, hidden layers which are connected to inpur layer through synapses of varying weights.Between the input layer and the hidden layer,we have an actication function which are of various types such as threshold function,rectifier function,hyperolic tangent function,etc.Before the output layer, a sigmoid function is applied as it is good at predicting probabilities.The neurons detect patterns in the data.After the output layer generates output, the predicted values and the actual values are compared using cost functions, and after computing cost function, we feed the obtained value back to the network,the weights of the synapses are readjusted consecutively depending on the learning rate and in the next run the predicted values change.The goal is to minimise the cost function.This process is called back propogation. Gradient descent is plotted and at the global minimum we get the optimal values of weight.The cost function must be comvex, if it is not convex we may face issues as we might get local minimum instead of global minimum. To resolve this issue, we apply stochastic gradient descent instead which does not require the cost function to be convex. Contrary to batch gradient descent where weights are adjusted by running all the rows, in stochastic gradient descent we take rows one by one and adjust the weights.When the whole of training set is passed through the artificial neural network it makes an epoch, we have to redo more epochs.

